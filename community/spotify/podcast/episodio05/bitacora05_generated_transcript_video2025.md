# Transcripci√≥n del video "Ruta Habilitadora DI ü§ñ LLMs y Prompt Engineering en Acci√≥n (Sesi√≥n 4 de 9)"

Dame el transcript de este video siendo fiel a las palabras que se dicen de inicio a fin. Ignora el tiempo, enfocate en qui√©n dijo qu√© y en qu√© orden y entregame el transcript de mejor calidad que puedas.

## [Video](https://youtu.be/QJjv8cdv-d4)

Aqu√≠ est√° el transcript del video, fiel a las palabras que se dicen y enfoc√°ndose en qui√©n dijo qu√© y en qu√© orden:

**Pipe:** y bueno chicos v√©anse poniendo c√≥modos ya pasaron un par de minuticos vamos igual a a respetar lo mejor posible el tiempo de todos ustedes espero que hayan tenido un buen puente que se hayan escuchado la la bit√°cora sint√©tica del s√°bado eh con el **emocionante d√≠a del reto** digamos se se entregaron bastante pull request esta ma√±ana que hay como **60 pull request y m√°s de 60 forks** en el repositorio eh tambi√©n le he estado subiendo algunos cambiecitos a la landing page del del repositorio pueden entrar ah√≠ a mirar todas estas sesiones van quedando ah√≠ grabadas y dem√°s as√≠ que eh nada si quieren vamos eh de una vez con la sesi√≥n que tenemos para hoy sobre Llms y Prom Engineering con nosotros est√° **Jonse Rodr√≠guez** e b√°sicamente √©l me lo recomendaron directamente desde el estudio de data precisamente porque ha estado cacharreando mucho con este tema eh hay una sesi√≥n que se hizo el a√±o pasado eh con Pablo se llama √©l sobre prom engineering lo que lo que va a hacer Juan es construir sobre esa sobre esa sesi√≥n que se hizo el a√±o pasado y expandir hay un mont√≥n de informaci√≥n que hay ac√° as√≠ que nada por ah√≠ estaremos conversando un poquito pero nada m√°s que nada darte el paso Juan para que puedas iniciar y y cualquier cosa que vayan teniendo de preguntas las ponen por favor en la casilla de preguntas y respuestas y y por ah√≠ estaremos d√°ndole espacio entonces Juan muchas muchas gracias y y bienvenido a esta charla de la ruta habilitada

**Juan:** bueno gracias Pipe y y gracias muchachos por sumarse eh vamos a ver durante esta hora bastante contenido bastante cosas pr√°cticas est√©n pendientes ah√≠ al final voy a requerir de ustedes para que me ayuden a escoger sobre qu√© vamos a hacer la demo eh eventualmente pues bueno vamos a hacer primero como un repaso general de los conceptos y vamos a aterrizar en temas te√≥ricos ¬ølisto esta charla pues est√° enmarcada eh en la parte del **despertar del equipo ag√©ntico** entonces est√°n de aqu√≠ al 29 en unas charlas eh donde el d√≠a de hoy nos trae justamente como dec√≠a Pipe a la charla de LLMs y Prom Engineering en acci√≥n ¬ølisto ¬øcu√°les son los temas que vamos a ver el d√≠a de hoy eh primero una una peque√±a introducci√≥n vamos a ver un tema relacionado a conceptos b√°sicos conceptos generales conceptos especiales y ya van a ver en qu√© se diferencian las tres cosas vamos a ver **qu√© es un buen promp ¬øqu√© es un buen promp ¬øqu√© es vibe coding** que seguramente si no lo han escuchado o lo van a escuchar o lo vamos a ver hoy en esta sesi√≥n vamos a hacer unas demos pr√°cticas y vamos a tener la parte de Q&A todo esto la idea es verlo en esta horita entonces pues les pido su mayor atenci√≥n cualquier duda que tengan en el proceso por favor d√©jen la caja de Q&A y lo vamos a ver al final de la sesi√≥n sobre m√≠ pues bueno eh como lo dec√≠a Pipen yo hago parte de Global estoy aqu√≠ hace m√°s de aproximadamente 5 a√±os me desempe√±o como business intelligence y trabajo con datos y con todos estos temas de anal√≠tica desde hace m√°s de 8 a√±os eh temas de AI y modelos ag√©nticos desde el a√±o pasado realmente pero pues van a ver que aqu√≠ en temas cuando uno habla inteligencia artificial el tiempo se mide en meses de un mes para otro las cosas cambian tremendamente evolucionan y pues bueno aqu√≠ lo que quiero es compartirles un poquito de las cosas que he venido aprendiendo y pues sobre todo darles como un overview general de el resto de las charlas y pues digamos de c√≥mo esto se interact√∫a y conecta con el resto de los temas que ustedes van a ver entonces teniendo eso en cuenta pues tengamos en cuenta que el objetivo de esta sesi√≥n que ustedes vayan como con un objetivo que es al final me van a decir si lo logramos o no es que se den un vistazo y repasen o conozcan conceptos te√≥ricos relacionados con LLMs y tambi√©n como existen hoy d√≠a diferentes herramientas que pueden servir durante todo el ciclo de vida de desarrollo de software que todo esto pensado en la **batalla del MVP** que pues como bien saben es el estadio final de esta convocatoria en la que est√°n trabajando junto con Pipi la charla en la que estamos hoy es la **cuarta charla de una serie de nueve charlas** como se pueden dar cuenta eh vamos a hablar sobre LLMC Prom Engineering hay varios temas que yo voy a tocar que van a ser expandidos m√°s adelante en las siguientes charlas entonces los invitamos a que no pierdan el hilo a que sigan conectados sigan participando y pues de una otra forma sigan aprendiendo y sobre todo al final logren aplicar todo lo que han venido aprendiendo con nosotros en estas charlas.

**Juan:** ahora bien empecemos hablando de temas relacionados con LLMs y vamos a empezar hablando con los **modelos de lenguaje ¬øqu√© son los modelos de lenguaje** son b√°sicamente un modelo que se basa en en probabilidades para adivinar probabil√≠sticamente cu√°l es la siguiente palabra que va a seguir de acuerdo a unas palabras que √©l tiene ya precalculadas ¬ølisto como podemos ver aqu√≠ eh tenemos un un nodo eh de una otra forma es el modelo de lenguaje vamos a ver que hay diferentes modelos de lenguajes pero todos al final funcionan de la misma forma todos tienen como esta misma sintaxis que b√°sicamente lo que hacen es de una forma estad√≠stica adivinar cu√°l es la siguiente palabra que va a seguir y con eso pues van a generar diferentes cosas mucho m√°s robustas m√°s adelante en t√©rminos de **historia de los modelos de lenguaje** esto si bien nosotros √∫ltimamente estamos hablando y escuchando much√≠simo de inteligencia artificial realmente quiero que sepan que este no es un concepto nuevo este concepto tiene casi **35 a√±os desde 1990** cuando empezaron a hablarse de modelos estad√≠sticos se empez√≥ a hablar de los eneagramas que viene a ser como la base de todo esto hay diferentes eh hitos que han venido pasando a lo largo de la historia en el **2000 nacieron los modelos de neuronales** que vienen a ser la base tambi√©n de lo que hoy d√≠a tenemos como los CLMs y ah√≠ ha venido avanzando bastante como yo les dec√≠a el tiempo aqu√≠ se mide en meses no en a√±os inclusive podr√≠a decir que a veces hasta en semanas cada mes cada a√±o han salido diferentes novedades diferentes modelos eh hoy por ejemplo vamos a enfocarnos much√≠simo en Google en **Gemini** pero pues Gemini no fue el primer modelo que sac√≥ Google √©l tuvo un modelo que realmente les fue muy mal que fue Bert o creo que ten√≠a otro nombre tambi√©n Bart jam Bart eso fue Bart y esto es ensayo de error y evoluci√≥n constante entonces eso tambi√©n es como algo de lo que quiero que se llen experimenta y fracasa y vuelve a intentarlo y tiene √©xito eso es como un ejemplo para nosotros en el mundo del aprendizaje para seguirnos preparando y aprendiendo como se pueden dar cuenta a medida que va pasando el tiempo y esto se qued√≥ corto y esto est√° junio del 2024 eh cada a√±o salen m√°s modelos salen m√°s tecnolog√≠as m√°s cosas que de una u otra forma nos invitan a seguir aprendiendo y a seguirnos cuestionando como bueno qu√© es lo que hay que aprender es lo que sigue teniendo en cuenta eso nosotros buscando en internet encontrar√≠amos much√≠simas infograf√≠as que son este tipo de cuadros de resumen desde el a√±o pasado y si se pueden dar cuenta se quedan obsoletas muy r√°pido porque aqu√≠ por ejemplo estaban comparando en ese momento hace un a√±o el √∫ltimo modelo de chat GPTR el 4o y era el 1.5 Pro y dem√°s eh Mistral y Cloud y Yaman con el de el de meta esto ha venido cambiando inclusive eh todo el tema de **GPT 5 que sali√≥ hace dos semanas** si mal no estoy tambi√©n ha cambiado el tema entonces todo esto lo pone uno a pensar y a decir "Bueno y de pronto sea una de las preguntas que ustedes se hagan aqu√≠ m√°s adelante y una ve se las quiero responder o darles el spoiler para el final vamos a ver la respuesta pero es bueno ¬øcu√°l es el que deber√≠a utilizar ¬øcu√°l es mejor eh Juan eh he escuchado que Jemen es muy bueno para esto pero de pronto Cloud es mejor con su modelo Sonet o resulta que alguien me habl√≥ de Mistral ¬øcu√°l es el que deber√≠a ser el mejor ¬øcu√°l es el que yo deber√≠a utilizar pues bueno lo vamos a ver y no va a ser yo el que les diga cu√°l es el mejor sino les voy a compartir una herramienta que les va a permitir a ustedes estar al d√≠a porque esto todos los d√≠as va evolucionando y pues la respuesta que hoy era el mejor modelo resulta que en una semana sali√≥ otra cosa nueva en otro proveedor y ese modelo cay√≥ al segundo puesto entonces este lo vamos a ver m√°s adelante y espero pues sea una de las primeras herramientas que se lleven de esta charla.

**Pipe:** hay hay un par de preguntas Juan ah√≠ las las introduzco rapidito y es preguntan **si los LLMs debemos crearlos desde cero o nos entregar√°n las bases** para que cada equipo pueda ajustarlo a las necesidades del MVP que van a crear en la Hatul y la verdad es que los LMS no se crean desde ceros cuesta un mont√≥n de plata entrenar un modelo de estos es algo que ya est√°n digamos como decimos out of the box o sea est√°n listos para usar ya depende uno si usa el modelo gratuito o alg√∫n tipo de suscripci√≥n o tal as√≠ funciona en general para todos los mortales en el contexto de la competici√≥n ustedes van a recibir las instrucciones sobre c√≥mo conectarse recuerden que hay tres lineamientos para conectarse **una conexi√≥n con API directa** a uno de estos modelos para lo cual se les va a suministrar una API Key y se les va a decir esta API Key funciona contra este modelo por ejemplo si consume algo en Bedrock si consume algo en Openii si consume algo en Cloud ya veremos se les va a dar una piqui para consumo directo y para los MCP y los A2A agent eh se les va a dar la URL hagan de cuenta como se fuera a consumir un restando una infraestructura que en su momento estar√° lista entonces partiendo en dos es los LLMs no es que nosotros hagamos nada desde ceros eso ya est√° hecho solo los usamos y dos para la competici√≥n no se preocupen que tendr√°n las instrucciones y de hecho se les estar√° liberando eh en las pr√≥ximas semanas y antes de la competici√≥n algunos ejemplos de c√≥mo por ejemplo tener el MCT Server y c√≥mo tener un cliente y ese tipo as√≠ que no se preocupen otro que dicen respecto a los modelos que hay centrados en codificar **¬øcu√°l crees que ser√≠a mejor hoy le√≠ que GPT5 no es muy bueno para programar y que tal vez Cloud sea mejor** eso ya en un momentito Juan lo va a responder pregunta alguien m√°s **¬øqu√© criterios recomiendan para elegir entre un modelo cerrado como GPT Yemina y uno abierto como Mistral o Lama en MVP en Majacaton** yo creo que tambi√©n se va a responder ahorita **¬øc√≥mo ser√≠a la mejor forma de estructurar un prom para que un modelo de lenguaje no solo me d√© la respuesta sino que tambi√©n haga un plan de acci√≥n paso a paso** que pueda yo usar ya segu√≠a con mi protocolo tal bueno c√≥mo escribir buenos promptos yo creo que vamos entonces en camino esas eran las pregunticas que hab√≠an hasta ahorita juan.

**Juan:** perfecto Pipe no y y gracias muchachos por sus preguntas todo eso est√° planteado en el ciclo de la llamada sigan poniendo sus preguntas eventualmente algunas ya van a ser respondidas eh traigo todo condensadito para que se vayan con las mejores respuestas ¬ølisto entonces todos estos temas que me preguntaron los vamos a ver en esta llamada ¬øvale por ahora sigamos entonces ahora pasando de los conceptos b√°sicos que era todo esto como podr√≠amos decir lo que y si se dan cuenta vamos a ir empezando a bajar al core del asunto **conceptos b√°sicos** hablan m√°s como de la industria en general vamos a entender ahora un poquito los conceptos b√°sicos y es **c√≥mo funciona un LLM ¬øqu√© es un LLM** ¬ølisto entonces todo esto se basa en un tema estad√≠stico matem√°tico como yo les dec√≠a y es la **representaci√≥n vectorial del lenguaje** cuando alguien le escribe eh una torre a o sea escribe la palabra torre por as√≠ decirlo en un en un promp en un cat puede estar pensando por ejemplo en esta torre que se parece mucho a la del Anill sin embargo si le da m√°s contexto le coloca otra palabra torre fel se pueden dar cuenta que por as√≠ decirlo ya la respuesta tanto lo que uno est√° pensando como lo que el el Ll est√° entendiendo apunta hacia otro lado y es b√°sicamente porque la representaci√≥n vectorial es lo que est√° detr√°s de todo esto ¬øc√≥mo funciona esto digamos muy por encima para que se entienda y pues el objetivo de esto no es tampoco que nos volvamos super estad√©sticos matem√°ticos pero s√≠ que entendamos las cosas y es que b√°sicamente cada palabra que tenemos en espa√±ol originalmente por esto funcionaba mejor en ingl√©s inclusive hay algunos modelos que hoy d√≠a todav√≠a le recomiendan a uno coloca el prompt en ingl√©s porque pues es donde m√°s tiempo lleva entren√°ndose el modelo como dec√≠a PIP eso es car√≠simo generar un modelo y por eso es que tiene un tema grand√≠simo una competencia donde muy pocas empresas son las pioneras hay otras como efectivamente eh Antropic y dem√°s que tienen muy buenas soluciones pero al final todo eso son n√∫meros detr√°s de las palabras entonces cada vez que nosotros colocamos una palabra dentro de un chat esa palabra se vuelve un vector de n√∫meros donde se coloca en un plano cartesiano de 3D entonces ah√≠ hay una relaci√≥n y de acuerdo a las palabras que vamos colocando el modelo va asociando y va diciendo por ejemplo el pasado de caminar fue eh de caminando fue camin√© o de nadando nad√© o el femenino de hombre es mujer y el femenino de rey es reina ¬øc√≥mo se gener√≥ eso pues eso es una historia largu√≠sima pero tenemos que saber que todos los modelos que actualmente existen ya fueron entrenados con todo el internet toda la base de datos de palabras que hab√≠an en internet hasta el 2023 y ah√≠ en adelante han hecho cargas incrementales y eso es lo que garantiza que esto funciona primero en ingl√©s nosotros pues ahora en espa√±ol y pues muchos idiomas por eso es que funciona porque al final todas las palabras de todos los idiomas se fueron bajando a un lenguaje num√©rico que se representa por medio de vectores ahora vamos a seguir con otro concepto que es clave para todo lo que vamos a ver y tiene que ver con la **arquitectura de Transformers** listo aqu√≠ si hay alguno que otro que le gusten las pel√≠culas como a m√≠ lo primero que va a pensar es "Venga Transformers Optimus Prime alguna cosa s√≠ tiene que ver por ac√° pero no." Realmente eh el tema de los Transformers es un modelo de arquitectura muy interesante que es la base de absolutamente todo lo que tenemos actualmente existi√≥ un art√≠culo de un tipo muy muy brillante que escribi√≥ un una pues por as√≠ decir un art√≠culo donde dec√≠a se llamaba **attention is all you need** todo todo lo que necesitas es atenci√≥n entonces √©l de una otra forma y pues yo muchachos este material lo vamos a compartir entonces no voy a ir punto por punto la presentaci√≥n la idea es que ustedes lo vean despu√©s sino mi objetivo es darles como contexto para poder caer en la demo pero pues b√°sicamente aqu√≠ lo que podemos ver es que eh los Transformers involucran un tema importante que antes no exist√≠a en ninguna arquitectura era el tema de la atenci√≥n y la atenci√≥n es b√°sicamente c√≥mo logro que esas palabras que est√°n vectarizadas tengan relevancia entre ellas s√≠ esto digamos que es como un un modelo por as√≠ decirlo de flujo donde se explica c√≥mo funciona el mecanismo de atenci√≥n sin embargo aqu√≠ lo importante que quiero que se lleven es que b√°sicamente esto es la clave de todo lo que funciona actualmente hace much√≠simos a√±os la inteligencia artificial como se acuerdan desde el 2000 fue que empez√≥ como a evolucionar ya llam√°ndose con el t√≠tulo de inteligencia artificial eh exist√≠an diferentes tipos de por as√≠ decirlo inteligencias artificiales enfocadas a diferentes casos de uso entonces hab√≠an eh temas de computer vision que ten√≠an diferentes arquitecturas hab√≠an otros que hac√≠an temas de natural language que es lo que nosotros hacemos actualmente que es traducir palabras de el lenguaje natural de humanos al de una m√°quina eh dictados eh eh traslaciones o traducciones y dem√°s esto era antes de que surgiera la arquitectura de Transformers ¬øqu√© pas√≥ ahora **todo lo que utilizamos ll√°mese Computer Vision eh Natural Language este es reinforcement learning que es como un mecanismo de de aprendizaje como aprendizaje de los LM todo funciona con la arquitectura de Transformers** ¬øy qu√© es la arquitectura de Transformers entonces esto es algo uno de los primeros conceptos importantes que tenemos que tener aqu√≠ que de hecho es la base y el que popular populariz√≥ esto fue **Open AI con Chat GPT** chat viene del concepto y como ellos imaginaron que ten√≠a que ser la interfaz para hablar con el modelo que era por medio de un chat y **GPT quiere decir generative pretrain transformers** entonces ¬øqu√© quiere decir en espa√±ol quiere decir eh modelos preentrenados generativos de Transformers eso quiere decir GPT openedi ha sido el primero que masific√≥ este concepto no es el primero o sea que lo desarroll√≥ como tal ¬øno pero si fue el primero que lo puso en el mundo p√∫blico y por eso es que todo el mundo nosotros as√≠ como pensamos en b√∫squedas en internet pensamos en Google cuando pensamos en en inteligencia artificial se nos viene chat GPT no es el √∫nico proveedor vamos a ver eso y pues bueno Pipe alg√∫n temillo ah√≠.

**Pipe:** sali√≥ **30 de noviembre del 2022** es el momento en el que eh Open masifica todo este tema y m√°s o menos que fue un tsunami que lleva a ver 23 24 llevamos menos de 3 a√±os en en que esto explot√≥ pero s√≠ lo que dice Juan ya exist√≠a desde antes el tema no sigue sigue solo quer√≠a dar la fecha eh igual esto lo van a estar viendo en diferido les recomiendo tomar notas repasar los materiales en fin.

**Juan:** excelente y s√≠ vamos a ver que esto el tiempo pasa aqu√≠ en meses muchachos pero bueno entonces desde ese tiempo ac√° ya inclusiveamos en GPT 5 que sali√≥ hace dos semanas no todo es color de rosa ya lo vamos a ver pero pues s√≠ es como el que siempre chat GPT va a ser el que est√° adelante que hay conceptos aqu√≠ interesantes que vamos a ver m√°s adelante el t√©rmino de **fine tuning** que es b√°sicamente c√≥mo est√° buscando chat GPT la evoluci√≥n del chat hacia un agente que es algo que tambi√©n creo que ustedes han escuchado bastante y que realmente es hacia donde va todo esto si ustedes me preguntan a m√≠ de aqu√≠ a un a√±o yo creo que ya vamos a estar hablando es m√°s que todo de agentes en lugar de modelos de LLMS pero siempre es bueno saber las bases y por eso es que esperamos que siempre que tengan dudas vuelvan a esta charla ¬øvale algo importante aqu√≠ con los Tomformers es que ellos dentro de su arquitectura que es un sistema como este esto obviamente es una abstracci√≥n pueden realizar tareas para la que las que no espec√≠ficamente fueron entrenadas ellos se alimentan como ya les dec√≠a de todo el cuerpo de datos texto que hubo en internet consumieron todo el internet entonces le cargaron todo el tema de videos de audio de YouTube por eso es que ahora ya hay una capacidad de generar im√°genes m√∫sica audio mucho m√°s amplia porque digamos que el conocimiento audiovisual que ten√≠a YouTube es incre√≠blemente poderoso y pues b√°sicamente los Transformers se volvieron la base para todo porque pueden justamente hacer esto no se focan como un chatbot que es como lo que antes ten√≠amos no se enfocan solo en una entrada para una salida sino pueden realizar mucho m√°s tareas que eso aqu√≠ otro de los temas que se nombran bastante con los LLMs esto naci√≥ este a√±o muchachos o sea esto es un t√©rmino que se populariz√≥ 2025 es el tema de los **multimodales** s√≠ antes hasta el a√±o pasado la mayor√≠a de los de los LLMs eran unimodales es decir recib√≠an texto que es como lo que llamamos un promp que ya vamos a ver c√≥mo se hace un buen promp y eh su output su salida era otra vez texto ahora ya podemos ver que hay modelos multimodales que b√°sicamente lo que hacen es dependiendo el tipo de insumo pueden tambi√©n resultar en diferentes tipos de outputs Generalmente nosotros lo usamos para texto pero pues ya se est√° masificando desde hace como dos meses el tema de video de audio y pues muchas otras funcionalidades como tal tambi√©n existen otros otros inputs que no son solamente las im√°genes no son solamente el texto sino las im√°genes el sonido cuando nosotros le hablamos todo esto al final la traducci√≥n que est√° haciendo esto por detr√°s se basa en los Transformers listo otro concepto importante que este s√≠ lo van a ver en mucha profundidad que les va a servir bastante muchachos para todo el tema de la digamos del MVP final y para su vida laboral es algo que justamente el el que el la persona que habl√≥ de Antropic eh sabe que ellos son est√°n dentro de su labor como independientes est√°n generando algo mucho m√°s evolucionado y m√°s visionario que es estandarizar todo esto hasta antes del **MCP que es el el model Ay no model protocol s√≠ model context aj√° model context protocol** hasta antes de esto nosotros ten√≠amos m√≠r ac√° est√° nosotros ten√≠amos que b√°sicamente aprendernos las API de cada una de las diferentes herramientas como ustedes saben y las APIs existen tambi√©n desde hace much√≠simo tiempo est√° SOAP est√° REST todos esos m√©todos de comunicar aplicaciones por medio de las API a√∫n existen a√∫n tienen validez a√∫n son muy importantes aprenderlas sin embargo lo que propuso Antropic es que para los modelos de agentes generar un nuevo modelo de protocolo que es b√°sicamente el MCP que lo que hace es unificar como en un gran directorio de APIs para que los agentes sean mucho m√°s f√°ciles la interacci√≥n con herramientas esto ya lo est√°n implementando muchas p√°ginas muchos aplicativos y pues esto es algo que van a ver con mucho m√°s detalle en una de las pr√≥ximas charlas de este contenido as√≠ que para cerrar esta primera parte de conceptos b√°sicos vamos a resumir todo en esta pregun en este slide que tienen ac√° la pregunta que ustedes hac√≠an y algo que quiero que se lleven es que hablar de AI es hablar de un mundo de cosas nosotros desde el punto t√©cnico tenemos que saber que los LLMs es el coraz√≥n de un mundo de tecnolog√≠as como podemos ver aqu√≠ aqu√≠ pues b√°sicamente pueden ver que la inteligencia artificial es realmente un universo que existe desde hace m√°s de 30 a√±os donde bajamos al tema de **machine learning** es b√°sicamente c√≥mo las m√°quinas pueden aprender sin tener que ser programadas espec√≠ficamente para una cosa van teniendo mecanismos de aprendizaje sin embargo esos mecanismos no pueden ser para no pueden ser secuenciales entonces es ah√≠ donde empiezan a crearse las **redes neuronales** que es b√°sicamente modelos de de paralelizaci√≥n del procesamiento de los datos ah√≠ es donde empiezan a aparecer los primeros pinos de todo el tema de los LLMs donde podr√≠amos decir que los chatbots eran una especie de red neuronal porque dependiendo x condiciones se toman diferentes caminos pero eso como lo vimos anteriormente evolucion√≥ con la arquitectura de los **Transformers** que es b√°sicamente empez√≥ como un uso de traducci√≥n autom√°tica y ya se volvi√≥ el est√°ndar de arquitectura de todas estas soluciones y llegamos al core que son los **LLMs** que son son en este punto en el que estamos son arquitecturas son elementos que nosotros utilizamos crear un LM es absolutamente caro dif√≠cil y realmente que en este punto si alguien dijera voy a salir con un nuevo modelo casi la mayor√≠a est√° arrancando en base de otros modelos por ejemplo est√° el caso de **Deepsek** que es este modelo chino que se dice que logr√≥ ser tan √≥ptimo pero porque tom√≥ varias fuentes de chat GPT y otros modelos que son de open source y gener√≥ desde ah√≠ pero entonces resumen de esto muchachos hablar de AI es hablar de un mundo de cosas y hablar de Lens es hablar correctamente lo que vamos a implementar en la soluci√≥n que ustedes van a hacer al final de este trayecto.

**Pipe:** hay una pregunta y Juan y es dice es **si los PR son siempre necesarios o depende de analizar la tarea** que queremos desarrollar que ha visto algunos p√°rrafos muy largos con varias secciones no s√© si se refiere a los p√°rrafotes que he puesto de proms en un repositorio donde todo lo que ha pasado esta ruta habilitadora se les ha publicado ya pero creo que la pregunta condens√°ndola ser√≠a **¬øhay alguna otra manera de darle instrucciones a un modelo de lenguaje que no sea lenguaje mismo a forma de instrucciones** porque tambi√©n m√°s arribita hubo otra comentario digamos que dec√≠an que se le daba un rol al modelo y se le pidi√≥ un plan paso a paso en un formato estructurado eh pero eso tambi√©n es pront entonces ¬øhay alguna otra manera de hacerlo o o simplemente cambi√≥ el paradigma en que le damos instrucciones a las m√°quinas y ahora no solo son lenguajes de programaci√≥n sino el lenguaje de programaci√≥n se volvi√≥ el ingl√©s porque es en lo que m√°s est√°n entrenando los modelos o espa√±ol que tambi√©n nos lo recibe eh con ciertas limitaciones ¬øqu√© qu√© dir√≠as a eso de siempre se necesita el trono.

**Juan:** bueno muchachos muy buena pregunta la respuesta es **no sin embargo lo que se hace de tr√°s escenas es convertir todo eso a a texto** s√≠ ustedes se han dado cuenta que por ejemplo ustedes pueden activar en Gemini en su celular Android y ustedes le pueden hablar y le pueden decir pueden activar la funci√≥n Live hablan con el modelo pero en realidad todo lo que est√° pasando por detr√°s es que se est√° volviendo texto y se sobreescriben las cosas entonces eh la forma de alimentar un modelo en este momento puede ser cualquier diferente tipo de fuente pues si es audio hay un algoritmo de Transformer que lo convierte en texto si es una imagen hay un algoritmo de computer vision se llama que lo convierte en texto y le describe las cosas y si es texto se convierte en texto entonces en resumen al final a este momento en este estadio en el que estamos de la arquitectura **todo es texto lo que le entra** para nosotros los humanos puede cambiar el formato pero al final lo que √©l recibe es texto porque todo esto se basa si se acuerdan amigos en el tema de la estad√≠stica y las palabras entonces por eso es que siempre en este punto vamos a hablar de promps es lo que en este momento son las instrucciones y ya vamos a seguir viendo m√°s adelante el tema de un buen promp espero se haya respondido la pregunta vamos a seguir ahora conceptos b√°sicos como les dec√≠a vamos a entrar otro poquito un nivel m√°s abajo hasta llegar al core que van a hacer los promps y tiene que ver con **conceptos generales** entonces cuando hablamos de un concepto general son unidades l√≥gicas m√≠nimas de conocimiento sobre la inteligencia artificial o sobre los LLMs aqu√≠ voy a empezar a mostrar 10 cositas son peque√±os bullets eh si usted sabe genial p√≥ngase un check internamente si logras responder las 10 o sabes las 10 es que est√°s muy bien informado si no pues hay que seguirse informando porque esto va cambiando las cosas que les voy a mostrar ac√° son la base para que ustedes sepan escoger cu√°l es el mejor modelo que deber√≠an utilizar de aqu√≠ en adelante primero vamos a hablar de los **tokens** entonces los tokens est√° es la forma como se monetiza como se controla como Open AI hace plata como Google hace plata ¬øc√≥mo se mide el procesamiento de esto antes nosotros habl√°bamos de gigas de megas de cualquier cantidad de informaci√≥n para los modelos del LMS la unidad m√≠nima es son los tokens si se dan cuenta los tokens se miden en texto no hay como un est√°ndar que yo les pueda decir "Mira es cada cuatro palabras es cada cinco." Eso va a depender un poco pues del tema de la palabra y tambi√©n del algoritmo que est√° por detr√°s pero algo importante aqu√≠ es saber que los tokens son la unidad m√≠nima con la que ustedes pueden saber qu√© tan bueno o malo es el input y el output de un modelo siguiente concepto es la **temperatura** entonces como yo les dec√≠a eso es un tema estad√≠stico y aqu√≠ se habla de dos conceptos determin√≠stico o no determin√≠stico y aqu√≠ b√°sica o o estad√≠stico por as√≠ decirlo eh la temperatura es un par√°metro que permite la aleatoriedad de las respuestas casi siempre la temperatura cuando uno est√° haciendo cursos de Llestran y le dicen es qu√© tan creativo es el modelo sin embargo la creatividad es muy subjetiva y aqu√≠ realmente es que tan del mundo matem√°tico de vectores que √©l puede proponerte como una respuesta ¬øqu√© tanto margen le est√°s dando a ti para que se abra entre las diferentes posibilidades que hay entre la torre Ifel y la torre del cerro de los anillos entonces eso es algo super importante a nivel de...

**Pipe:** Tengo tengo un apunte chiquitico con temperatura bueno si me permites eh piensen en esto una **temperatura cero es que sea tan preciso** como como se pueda entonces si por ejemplo ustedes van a generar no s√© c√≥digo SQL para insertar en alguna tabla o lo que sea pues va la temperatura cero porque si le ponen m√°s temperatura es posible que la respuesta se empiece a inventar un campo se empieza a inventar que la tabla se llame distinto lo que sea entonces **cosas de mucha previsi√≥n como por ejemplo generar c√≥digo deber√≠a tener baja o o ninguna temperatura** por el otro lado lo que se acerque a uno es que sea creativo entonces si yo digo "Gen√©rame una historia con una torre" pues capaz que mezcla la de Piza con la de Babel con la Ifel y se genera una cosa en Marte y por eso es porque tiene la oportunidad de de divagar mucho m√°s y ser m√°s creativo estad√≠sticamente hablando entonces piensen en eso eh cosas de precisi√≥n temperatura de acero tal cual.

**Juan:** eso es super importante lo vamos a ver m√°s adelante porque de acuerdo al estadillo en el que estemos en el ciclo de desarrollo de software vamos a necesitar tener lluvia ideas o vamos a necesitar encontrar errores o o proponer cosas concretas entonces aqu√≠ el tema de la temperatura es super importante.

**Pipe:** juan que hay una pregunta que dice que **si la temperatura depende del pron no es algo que siempre se pueda alterar ¬øcierto** si uno est√° en una cuenta gratuita con un con un dipsc o lo que sea uno puede modificar esa temperatura en el prom t√∫ sabes porque yo he visto que en las herramientas de Global hay un hay cheo hay donde modificar el par√°metro pero ¬øc√≥mo se altera la temperatura si no hay par√°metro ¬øse puede ¬øt√∫ lo has visto.

**Juan:** s√≠ eso va a depender digamos la temperatura es de acuerdo al modelo hm 0 y 1 es en la gran mayor√≠a pero yo en un hay un no me acuerdo qu√© modelo fue que yo encontr√© que la temperatura iba de -1 a 1 y cero era el punto neutro entonces digamos que eso cada proveedor lo coloca generalmente eso se hace desde la parte de la configuraci√≥n s√≠ casi siempre los usuarios la ventana que tenemos nosotros de cara al usuario final no permite modificar eso sin embargo en la parte desarrollo se puede hay varios modelos y y sobre todo digamos los chicos que son m√°s t√©cnicos muchos modelamos y se van a dar cuenta que yo pues no esto no est√° patrocinado por Google pero a m√≠ me encanta trabajar con GCP eh pero por ejemplo Google tiene un modelo que se llama **Yema** que ustedes pueden descargar y eh lo instalan en su m√°quina obviamente pues el de acuerdo a la m√°quina que tengan porque eso igual procesa y se demora bastante pero en esos modelos que ustedes son open source ustedes s√≠ pueden jugar con absolutamente todos los par√°metros hay otros modelos donde de acuerdo a la cuenta si es la cuenta free no la eh gratis no la podemos modificar pero hay otras herramientas que les vamos ahorita una de Google por ejemplo donde ustedes pueden jugar con el la temperatura y y con otro par√°metro inclusive y darse cuenta c√≥mo cambian las respuestas vamos a ver en un ratito tambi√©n en la demo pero es excelente pregunta eso est√° parte de atr√°s lo mismo que el siguiente que es muy importante que es la **ventana de contexto** y esta ventana de contexto es la **cantidad de texto que el modelo puede procesar a la vez** s√≠ a veces nosotros decimos "Ah mira es que chat GPT se acuerda de m√≠." Porque yo le dije "¬øTe acuerdas descr√≠beme en una palabra." Entonces visionario no s√© qu√© a veces nosotros decimos "La la inteligencia artificial se acuerda de m√≠." Y la realidad es que ni tanto porque eso es otro concepto que s√≠ tienen los agentes que se llama la memoria los LLMs lo que tienen son ventanas de contexto entonces ellos almacenan n cantidad de tokens esos se miden tokens y eso es lo que pueden almacenar tanto de entrada para condicionar la salida ¬ølisto entonces **¬øqu√© hace un modelo mejor que otro ¬øqu√© hac√≠a Gemini 2.5 Pro el mejor modelo era porque su ventana de contexto era 1 mill√≥n de tokens versus chat GPT que si mal no estoy ten√≠a 240,000 tokens** entonces la ventana de contexto es otro argumento que est√° por detr√°s y ese no lo podemos modificar nosotros es lo hace el que genera el LLM pero pues es importante tambi√©n para saber qu√© modelo es mejor que otro hay otro concepto que tiene que ver con los **embedings** que capaz eso ya es un poco m√°s t√©cnico pero tiene que ver con justamente el tema que les explicaba antes de la Torre Ifel y la torre del Se√±or de los Anillos y es c√≥mo se representa num√©ricamente los datos en un espacio vectorial por eso era que yo les dec√≠a que hasta este momento no importa el input que nosotros le demos todo eso se vuelve texto y de texto se vuelve lenguaje binario unos y ceros de pasando por una capa matem√°tica en el medio entonces los embings el t√©rmino t√©cnico de todo este procesamiento vectorial quinto tema y pues me van diciendo despu√©s si pueden ir poniendo cu√°ntos temas van hasta este punto y es el tema de **prom engineering** que es tambi√©n est√° relacionado con el nombre de esta charla y es b√°sicamente la t√©cnica de dise√±ar entradas para los modelos de AI entonces esto inclusive ha evolucionado tanto con los √∫ltimos modelos desde hace 2 meses se habla de **context engineering** o sea ya el promp engineering evoluciona y ahora se habla de context engineering ¬øpor qu√© porque los nuevos modelos tienen ventanas de contexto m√°s grandes entonces yo ya no me voy a sesgar a un prom muy chiquitito sino puedo irme por algo mucho m√°s grande para darle mayor contexto puedo procesar m√°s libros m√°s datos a la vez entonces esto tambi√©n es un tema y lo puse ah√≠ en negrilla porque est√° evolucionando tambi√©n y yo creer√≠a que al otro a√±o vamos a empezar a escuchar mucho m√°s de context engineering que de prom engineering.

**Pipe:** dale solo un comentario chiquito acu√©rdense que esta categor√≠a est√° dise√±ada con el estado del arte de la inteligencia artificial este a√±o al servicio de desarrollar un MVP de eso se trata desarrollo integral as√≠ que esto de **context engineering lo escuch√© por primera vez hace como un mes** y efectivamente todo lo que hab√≠a para detr√°s era prom engineer inventeado entonces con el tema del context piensen en **notebook LM** el que es una herramienta que ya les mostramos ac√° alguna vez en pantalla eh dependiendo de la suscripci√≥n que no tengan Google puede sumar hasta 300 fuentes de archivos textos videos de todo y esas fuentes sirven como contexto para el chat que uno haga y por ejemplo que saben que ah√≠ tambi√©n hemos generado el podcast de bitcora sint√©tica y ah√≠ uno puede generar el podcast con otro prom entonces **ya no es solamente como hacer un megaprom muy bien hecho** as√≠ como dicen que son unos prom largos que revisten las preguntas sino que adem√°s esos proms ahora pueden estar dentro de contextos para quien aqu√≠ haya tenido una cuenta plus de chat GPT sabe que tambi√©n se pueden crear proyectos y los chats que est√©n dentro de esos proyectos tienen acceso a unos archivos de conocimiento entonces ¬øc√≥mo estructurar ese contexto ¬øc√≥mo darle esas eh repito ese contexto al al modelo cada vez se vuelve m√°s importante bueno yo ¬øc√≥mo organizar los archivos ¬øson archivos enormes o los parto en pedazos ¬øc√≥mo hago para que el modelo se pueda enfocar en una cosa y no se pierda entre un mont√≥n de documentos e eso cada vez va a tener m√°s relevancia y es como la evoluci√≥n como dice Juan del del PROM Engineering.

**Juan:** correcto Pipe muchas gracias as√≠ es muchachos esto sigue evolucionando vamos a la sexto concepto tiene que ver con el **fine tuning** y esto es algo tambi√©n que est√° relacionado con el ROM Engineering que conocemos actualmente y esto es b√°sicamente **c√≥mo se ajusta un modelo que ya est√° preentrenado a un nuevo conjunto de datos** esto lo podemos ver mucho con los chicos que les ha gustado no s√© si han experimentado con Google Gems o con chat GPTT de los GPTS y es b√°sicamente como un modelo O3 o de que era el de Open AI que era el mejor hasta hace unos meses era el mejor O3 a pesar de que exist√≠a el 4o y dem√°s o como un Gemini lo adaptamos a un conjunto de datos m√°s peque√±ito entonces ese fine tuning es ese proceso que realmente aqu√≠ es donde las empresas como Open AI y Meta contratan much√≠sima gente y este procesamiento de fine tuning cuesta much√≠sima plata porque eso es un modelo de ensayo y error donde le preguntan al modelo cosas y esperan resultados ¬øno la respuesta venga yo le cambio la instrucci√≥n le cambio el conjunto de datos y dem√°s entonces Fine Tuning es un modelo es es el ajusta el el alistamiento que se hacen de los modelos y aqu√≠ es donde se realizan algunos problemas que vamos a ver m√°s adelante aqu√≠ en este paso es donde algunos modelos han empezado a tener alguno que otro problema siguiente punto importante son los **racks** los racks quieren decir **retrieval augmented generation** quiere decir b√°sicamente notebook LM que ahorita lo acaban de nombrar es un ejemplo perfecto de un RAC y esto es eh **generaci√≥n de conocimiento basado en archivos** s√≠ esto b√°sicamente lo que aqu√≠ se hace es decirle a los modelos miren le voy a dar este PDF le voy a dar el √°lgera de valdor gen√©reme solo con ese conocimiento las siguientes preguntas resp√≥ndeme cu√°l es la la los casos de factorizaci√≥n que s√© m√°s entonces los racks es la es b√°sicamente notebook LM es un un ejemplo perfecto de lo que es un rock y es b√°sicamente lo que le venden a uno como hable con sus archivos siguiente concepto importante aqu√≠ es el **chain of thought** que quiere decir **cadena de pensamientos** y este concepto est√° ah√≠ como en la mitad ¬øpor qu√© porque esto es lo que nos permite empezar a hablar de agentes ¬ølisto como yo les dec√≠a yo creo que el otro a√±o todo va a ser alrededor de agentes ya cuando el MCP el protocolo MCP sea como el est√°ndar todo va a empezar a hablarse de agentes y este chain of thought es b√°sicamente esto es algo que ya implementa los √∫ltimos modelos y es una arquitectura que lo que le permite a los modelos y despu√©s a los agentes es **empezar a trabajar por pasos** s√≠ aqu√≠ en este eh lo que vemos actualmente se aplica en cuando le decimos un modelo que piense que razone hay una opci√≥n que uno le puede activar que le puede decir deep eh deep research o o le un tema diferente que lo que hace √©l es **piensa antes de responder** este tipo de opciones actualmente toman un poquito m√°s de tiempo pero se utilizan bastante cuando lo que yo quiero es una respuesta super bien elaborada m√°s que todo se hace en la generaci√≥n de texto ¬øno porque es ah√≠ donde hay que pensar mejor las soluciones sin embargo en el desarrollo tambi√©n mejora bastante los resultados cuando uno activa el modo de deep research o diferente cada proveedor tiene un nombre pero es esto al final es este tema que est√° detr√°s que el enfoque que permite razonar paso a paso siguiente concepto importante son los **vallas en ingl√©s vallas que uno lo escucha much√≠simo son los sesgos** y esto aqu√≠ es b√°sicamente cuando un modelo tiene alg√∫n prejuicio y esto se ruido se mete al modelo por medio de los datos de entrenamiento aqu√≠ hay Google fue especialista en embarrarla al comienzo con sus primeros modelos porque ten√≠an much√≠simos sesgos hay muchos casos si ustedes buscar√°n eh en internet historia de sesgos han habido bastantes hay por ejemplo recuerdo hay uno que le pas√≥ a Amazon y tiene que ver con la con la gente digamos echaron a la gente de recursos humanos para contratar personas y lo hac√≠an por medio de modelos de Llens eso fue en el 2022 este a√±o volvieron a contratar a toda la gente de recursos humanos ¬øpor qu√© porque se dieron cuenta que el modelo que ellos utilizaban para seleccionar personas en su conjunto de entrenamiento la mayor√≠a si no decir el 90% de los datos eran cargos donde los hombres eran las personas que estaban en el cargo de ingeniero de desarrollo de pruebas etc un largo etc claro cuando el LLM entraba y validiaba dos personas pod√≠an haber dos personas con perfiles muy muy similares pero √©l ten√≠a un sesgo y era que estad√≠sticamente el ingeniero de Cuban siempre era un hombre ¬øpor qu√© por todo este tema que ya vimos atr√°s entonces ¬øpor qui√©n escog√≠a al hombre y dejaba por ese lado entonces temas del sesgo es un tema que todav√≠a existe todav√≠a pasa bastante se introduce en el en el mundo del conjunto de entrenamiento pero pues es algo que eventualmente hay inclusive profesiones que se basan en trabajar para reducir ese CESCO y por √∫ltimo para ya empezar a entrar a la carne de la charla que nos quedan 15 minutos son los **agentes** y estos agentes pues b√°sicamente eh lo que difiere con un chat GPT es que un agente tiene la opci√≥n de percibir el entorno puede ser por promps puede ser por sensores toma decisiones por medio de cadenas de pensamientos pero tambi√©n act√∫a en funci√≥n de objetivos s√≠ actualmente chat GPT gener√≥ el activ√≥ el modo gente ya existe en otros lados la gente que es muy t√©cnica conoce por ejemplo **Lchain** que es un es un modelo de de para digamos orquestar agentes donde ya exist√≠a esto es open source les recomiendo que lo revisen si no lo conocen landchain el s√≠mbolo es un lorito muy interesante tiene librer√≠as y dem√°s y se puede utilizar en Python pero pues al final un agente es esto es el siguiente paso y es c√≥mo los modelos pueden ser el cerebro de algo que interact√∫e con otras herramientas o con el entorno ahora v√°monos...

**Pipe:** hay un par de preguntas yo s√© que vamos apretar de tiempo pero dicen que el seis y el siete no le qued√≥ claro as√≠ que voy a intentarlo el tema del **fine tuning es recuerden que los modelos de lenguaje tienen unos pesos internamente esos pesos son los que determinan estad√≠sticamente por d√≥nde va a ir la red neuronal para responder entonces cuando alguien hace fine tuning lo que est√° haciendo es agarrar uno de estos modelos y en una parte del modelo le altera los pesos internos para que se comporte diferente** es decir para que basado en lo que ya sabe algo lo sepa hacer un poco mejor tune√°ndolo hagan de cuenta como cuando uno tuneaba un radio a punta de cambiarle los pesos reajustarle los pesos al modelo y en cuanto a los **racks piensen en Leonardo en el repositorio est√° Leonardo leonardo no es otra cosa que un ragazistan que va sobre un par de PDFs y √©l tiene un prom que le dice c√≥mo responder basado en esos PDFs** pero no es otra cosa que es unos documentos y un promuario basado en esos documentos y hay una pregunta aprovecho y te la hago Juan dice "**Tengo entendido que existen otros tipos de modelos los Transformers y los de difusi√≥n que generalmente se han utilizado para generaci√≥n de im√°genes que es perfeccionamiento de ruido actualmente he visto que existen modelos de lenguaje pero con arquitectura de difusi√≥n que si tienes alg√∫n concepto relacionado con eso digamos fuera de los Transformers ¬øtienes algo** al menos para comentar ser√≠a eso y ya te saco m√°s que...

**Juan:** Excelente pregunta s√≠ digamos que antes exist√≠a inclusive me acuerdo que hab√≠a un un proveedor que se llamaba **Stable Diffusion** que era m√°s enfocado en im√°genes sin embargo ¬øqu√© les puedo decir yo hay modelos inclusive Open AI ten√≠a herramientas diferentes existi√≥ un Leonardo tambi√©n que era de generaci√≥n de im√°genes todav√≠a existen son muy buenos pero al final digamos que lo que se est√° estandarizando son los Transformers si existen otros tipos de arquitectura est√°n enfocados en otro tipo de casos de uso pero si ustedes se dan cuenta desde que se introdujo el concepto de multimodalidad ya los resultados son muy buenos hm ya GPT s√≠ tiene un tema y es que no importa lo que ustedes generen tienen como un una paleta de colores tiene un estilo que uno dice "Esa imagen la gener√≥ CH GPT." diferentes table diffusion u otros tipos de arquitecturas que est√°n enfocadas en eso no podr√≠a profundizar m√°s porque honestamente digamos yo les comento desde la experiencia lo que m√°s he visto digamos que en este mundo de procesamiento de datos que era lo que yo les dec√≠a el tema de de Business Inteligen es mi background todos la mayor√≠a de modelos que en los que yo he trabajado tienen por detr√°s la arquitectura de Transformers pero s√≠ est√° muy bien y gracias por la pregunta porque s√≠ existen otras arquitecturas para otros tipos eh casos de uso.

**Pipe:** y hay una pregunta cortita **diferencia entre Fine tuning y usable from Engineering** tambi√©n le respondo rapidito fine tuning cambia los pesos de un modelo incluso no piensen solo en los grandes modelos de lenguaje sino pueden ir por ejemplo a una p√°gina que se llama **how Face** que no s√© si est√° en alguna parte del material que trajo Juan y uno puede bajar por ejemplo un modelo que me ayude a hacer computer vision de piecitas de cierto tipo para yo meter eso en una f√°brica e identificar alg√∫n producto defectuoso y yo puedo agarrar ese computer vision y hacerle fine tuning para que entonces me ayude a alg√∫n producto muy colombiano de artesan√≠as porque resulta que el modelo original open source no lo ten√≠a entonces **cambiar pesos find tuning mientras que prom engineering los pesos siguen siendo los mismos y est√° uno como en una capita por encimita no tan intrusiva en el modelo funing es m√°s dif√≠cil tiene m√°s trabajo mientras que prom o context engineering implica trabajar con lo que el modelo tiene en cuanto a pesos y ya**.

**Juan:** perfecto y aprovecho no est√° dentro del del contenido pero si es muy bueno y eso tambi√©n es una invitaci√≥n que les hago muchachos y es hay que saber de todo un poquito eh eh **Hogin Face es buen√≠simo para los que son muy desarrolladores porque ustedes pueden descargar de ah√≠ los modelos** la mayor√≠a todos los modelos digamos lo que les dec√≠a Google tiene Yema Open AI tiene el GPTS que tiene dos sabores diferentes dependiendo del procesamiento pero Hogin Face es una buena fuente donde ustedes pueden tener un modelo cuando son open source se permite hacer eso que dec√≠a Pipe y es venga yo c√≥mo le doy un segundo uso a eso que ya alguien m√°s cre√≥ eso es como la magia del open source bueno ahora vamos a ir a los **conceptos especiales** ya para entrar en pleno de los promps y voy a ir muy r√°pido y esto son cosas que solo ustedes van a aprender en la pr√°ctica y es algo que yo he visto solo empezando a trabajar con esto lo primero y tiene que ver con el **costo el costo de los tokens** entonces los tokens siempre el costo del output es mayor que el de la entrada ¬øpor qu√© porque pues est√° basado digamos en todo el trabajo que est√° cobrando Google Open AI por el la investigaci√≥n que hicieron ¬øno entonces por eso aqu√≠ es importante que ustedes sepan que los tokens es la unidad de medida de esto de uso porque de acuerdo a eso si ustedes por ejemplo hacen pruebas y colocan una tarjeta de d√©bito que uno la puede colocar como de cr√©dito y se le va la mano pues resulta que le van a empezar a cobrar duro porque los tokens es la unidad que uno tiene que estar ech√°ndole ojo cada rato hay otro concepto que tiene que ver con el **context Riot** que es b√°sicamente justo como estamos hablando y es **entre m√°s contexto yo le doy a un a un a un modelo hay m√°s posibilidad de que se confundan hay posibilidad de que responda mal** s√≠ esto ha empezado a suceder esto es un concepto casi nuevo empez√≥ desde el mes de julio cuando con el lanzamiento de Gemini 2.5 Pro empezaron a ver como publicaciones relacionadas con esto y por eso es que el context engineering empieza a tener m√°s auge porque no se trata de botarle m√°s texto sino tiene que haber una t√©cnica tambi√©n para que el texto que se coloque all√≠ sea un texto que genere valor y no confusiones o lo que se conoce en el mercado como **alucinaciones** s√≠ las alucinaciones son respuestas que est√°n basadas en no son digamos no entran como esa parte de la creatividad de la temperatura sino son respuestas que se saben que est√°n mal pero que la IA asume como verdaderas y pues esto es un tema con lo que luchan much√≠simas empresas para eso tambi√©n contratan muchos ingenieros y cuando uno hace el tema de fine tuning tambi√©n est√° luchando contra las alucinaciones porque es justamente como logro el modelo no empieza a generar datos basura o cosas que no son las que yo le pregunt√© otro tema importante aqu√≠ y eso es lo que diferencia un modelo caro de uno open source si hay que hacer las cosas como se dicen es el tema de la **latencia y la escalabilidad** ¬ølisto la latencia es que tanto tiempo se demora en responder un modelo y eh y eso se afecta de acuerdo a la carga de los usuarios entonces por eso es que hay modelos que son m√°s caros porque ellos garantizan una latencia menor sin importar la carga de usuario entonces digamos que cuando existe un modelo Pro y el modelo gratuito lo que pasa es que en el modelo Pro la arquitectura detr√°s de esos que ofrece Open AI Gamini o el que sea Cloud lo que est√° garantizando es que la respuesta es menor porque tiene una mejor arquitectura entonces eso es algo importante ac√° sobre todo cuando uno trabaja con much√≠simos datos y lo √∫ltimo era el tema que les comentaba el tema que solo se da cuenta uno en la pr√°ctica y es el tema del **sesgo** el sesgo existe tambi√©n inclusive en los datos a veces hay inclusive operaciones matem√°ticas eh hay gente que tiene mucho tiempo y se pone a probar y hay operaciones matem√°ticas que las inteligencias artificiales no resuelven bien y es porque puede haber un sesgo tambi√©n en la falta de la definici√≥n del promp sobre eso hay un tema importante que es el tema de los **WRIALS** que esto es c√≥mo se logra que los modelos no se salgan del contexto de la reglas que les estamos generando y ahora bien vamos al cor de esta presentaci√≥n ya pensando en la demo que se nos est√° corriendo el tiempo y es los **buenos proms**.

**Juan:** entonces yo siempre yo en mi trabajo le tengo que explicar a gente de negocio c√≥mo empezar√© a utilizar inteligencia artificial y esto se me hace que es el mejor ejemplo y es cuando estuvo de moda todos estos memes y es que es b√°sicamente si nosotros no sabemos c√≥mo preguntar el genio de la l√°mpara ll√°mese Gemini Chagipt va a responder mal entonces por eso es que los buenos proms existen yo encuentro aqu√≠ esta y esto responde una de las preguntas si pueden m√©tanle un pantallazo a esto o cuando les compartamos el material rem√≠tanse en este slide y es b√°sicamente que deber√≠a tener la estructura un buen promp esto est√° actualizado a GPT 5 que digamos que es por ahora la √∫ltima reinvenci√≥n pero b√°sicamente tiene **seis elementos** ¬ølisto lo primero como alguien lo dec√≠a y lo ideal es que vayan en este orden h el contenido puede variar digamos que eso es una plantilla pero siempre tengan en cuenta muchachos sobre todo ahorita que est√©n pensando en ideaci√≥n de ideas t√©cnicas o o de productos viales esto es super importante primero hay que asignarle un **rol** ac√° el ejemplo digamos si ustedes pueden ver y el que tenga conocimiento de ingl√©s lo voy a ver en detalle sino pues ac√° lo que se explica es que est√° generando es como una un gu√≠a de viajes y ac√° le est√° dando las diferentes condiciones para caminar o o rutas de caminatas ¬ølisto entonces ac√° por ejemplo podemos ver que los seis elementos claves son asignarle un rol darle una **tarea** que es b√°sicamente qu√© es lo que ustedes esperan de √©l hm darle un **contexto** que es toda la parte digamos como qu√© es lo que es relevante s√≠ a veces digamos puede que yo tenga una base de datos donde yo le diga miren la tarea es sumar encontrar las ventas pero resulta que el contexto es que hay tres columnas y una es la de venta sin IVA y resulta que en mi pa√≠s lo que importa es el monto sin IVA entonces usted me va a sumar no todas las columnas sino necesito que todo lo haga en base a la del cinema por ejemplo le tienen que dar por ejemplo ac√° un cerca del contexto est√° el **razonamiento** y es b√°sicamente por ejemplo eso lo he visto mucho que falla a veces por ejemplo cuando uno no le dice al modelo que genere gr√°ficos por ejemplo lo hace mal si uno no le explica por ejemplo miren el eje X tiene que ir de tal forma el eje Y de tal forma si el n√∫mero es muy grande tiene que acortarle y decirle "Qu√≠tele los decimales." Todas esas cosas hacen parte del racionamiento y eso es algo que uno casi nunca hace que es muy importante y es decirle cu√°l es el **tipo de formato** que uno necesita hm porque eso va a condicionar tambi√©n c√≥mo el modelo va a responder entonces es importante esto y por √∫ltimo que tampoco casi nadie nunca hace es las **condiciones para parar** ¬øs√≠ entonces estos seis elementos muchachos son supercaros y aqu√≠ lo que les quiero dejar ac√° en este slide es estos dos puntos primero eh hay que generar una lista de tareas siendo muy espec√≠fico en cada una de ellas para que no nos pase como el meme del genio y lo m√°s importante es indiquen c√≥mo quieren su respuesta ¬ølisto acu√©rdense que si de acuerdo a lo que esos son modelos determin√≠sticos de acuerdo a lo que ustedes pidan es como √©l les va a trabajar y les va a dar resultados entonces esto es algo superimportante siguiente punto antes de la demo ya por favor les pido que vayan alistando sus celulares porque necesito que entremos a una p√°gina vamos a hablar de **vive coding** esto es un t√©rmino que naci√≥ a partir de febrero de este a√±o o sea estamos hablando 2025 de la mano de este se√±or que llama **Andrew Carpati** este tipo era un man era una persona un ingeniero senior dur√≠simo en Openi y se lo llev√≥ Tesla como director de inteligencia artificial entonces √©l es una eminencia y √©l dijo un d√≠a oiga vibe coding es como por as√≠ decirlo como seguir el flow la vibra s√≠ entonces el tipo dijo es muy ch√©vere porque con un modelo de inteligencia artificial yo puedo programar sin necesidad de saber programar entonces eso se volvi√≥ como en este ciclo que es un ciclo que se repite y es de una otra forma le digo al modelo oiga voy a escribir qu√© es lo que quiero hacer por favor genera tal cosa el modelo lo generan yo reviso y digo "No sabes que esto no me gust√≥ venga aj√∫stale esto." √âl lo redefine y al final lo implementa es decir le dice a uno "Oiga est√°n bien los ajustes listo vamos a crear esto." Pum y eso se vuelve un ciclo hay personas que y por eso lo puse la manzana en la discordia hay gente que le gusta y gente que no le gusta gente en contra los ingenieros de desarrollo puristas dicen pucha y estoy yo de acuerdo con ellos y es que **no hay que ser 100% VIPe coding** y sobre todo ustedes muchachos si en la llegaran a la final y alguien les dice "Mu√©streme el c√≥digo y expl√≠queme qu√© hace esta l√≠nea" y ustedes no saben habla muy mal de ustedes como profesionales porque uno no puede dejar que el LLM implemente el 100% de las cosas por uno acu√©rdense que la idea de esto son equipos sint√©ticos ¬øno donde trabajamos en conjunto no que la m√°quina haga todo entonces por eso es que el BY coding por un lado es malo en el sentido de que cuando se va a producci√≥n todo este c√≥digo que se genera **no necesariamente es el mejor c√≥digo puede tener brechas de seguridad brechas de performance** puede necesariamente no ser la mejor soluci√≥n funciona as√≠ pero no necesariamente con los aspectos t√©cnicos que necesita una aplicaci√≥n o algo en el en el ambiente productivo pero por otro lado es bueno porque **habilita personas que est√°n aprendiendo a aprender m√°s r√°pido** y eso es lo que vamos a hacer en la demo de ahorita muchachos entonces vamos a hacer la primera demo ah primero ac√° ten√≠amos un un meme que est√° enfocado tambi√©n como el tema de by coding vamos a saltar esto b√°sicamente y vamos a empezar la demo entonces necesito que porfa en su celular computador lo que sea esto es una encuesta rapid√≠sima es m√°s para determinar cu√°l va a ser la demo que vamos a utilizar el d√≠a de hoy necesito que entren por favor a la p√°gina **mentimeter.com** esa paginita es una p√°gina muy simple mentimeter como se escribe ac√° punto comom y ah√≠ ustedes van a colocar este c√≥digo **2686 862** listo voy a dar un minutito nos vamos con los votos que est√©n ah√≠ la idea de esto es que veamos voy ac√° a pausar la presentaci√≥n para poder pasar a la demo es mostrarles c√≥mo podemos empezar a utilizar herramientas de Lls dentro de diferentes partes del ciclo de desarrollo ¬ølisto hasta este momento les voy a compartir ac√° vamos a dejar como un minutico ya puse mi voto ah√≠ por Silas voto listo todos suman todos suman les muestro les pido muchachos que entren coloquen su voto eh mientras tanto hay una hay un comentario pregunta preguntas por favor dice...

**Pipe:** "**El coding en s√≠ no es malo pero se debe saber programar para poder revisar lo que hace la IA es decir una app desarrollada con bycoding puede estar lleno de BAC y brechas de seguridad si no se revisan** de hecho eso tiene un nombre deuda t√©cnica si uno no sabe bien qu√© es lo que est√° haciendo ah√≠ y lo incorpora en un sistema en producci√≥n sin criterio la deuda t√©cnica va a empezar a crecer eh por montones aunque tambi√©n hay gente medio dividida con esto hoy en d√≠a hay gente que dice que el software del c√≥digo se va a volver cada vez m√°s desechable es decir que no les importa mucho que est√© creciendo la deuda t√©cnica eh por lo que est√° pasando con la digamos que ah√≠ el debate est√° servido porque como les dije esto est√° pasando reci√©n este a√±o y les trajimos lo √∫ltimo de lo √∫ltimo en esta categor√≠a de desarrollo integral.

**Juan:** correcto s√≠ entonces s√≠ yo personalmente pienso que que el tema de la deuda t√©cnica basado en mi experiencia es es como cargar una maleta llena de peso irse de viaje dos d√≠as y cargarle el equipaje de un mes o sea eso es una cosa que no deber√≠a pasar se acumula con el tiempo y pues no realmente no va a salir nada bueno de ah√≠ yo pienso que estamos ah√≠ como en un medio medio pero bueno muchachos tenemos un empate no s√© si tenemos alg√∫n voto decisorio aplicaci√≥n de delivery o tracking de salud dejemos pipe ah mira tracking de salud listo vamos a cerrar las votaciones ah√≠ en aras de de de poder hacer las pruebas bueno entonces todas estas herramientas que les voy a mostrar todas son gratuitas todas son por detr√°s un LLM que hace algo est√°n enfocadas en diferentes partes del ciclo de desarrollo ¬øcierto ac√° como lo que dijimos digamos que vamos a utilizar es vamos a enfocarnos en toda la demo que vamos a hacer enfocada en la aplicaci√≥n de un **tracking de salud** ¬ølisto entonces la primera herramienta que les quiero mostrar amigos es esta herramienta se llama **database build** esta est√° creada por una empresa que llama **Supabase** que esto es una empresa digamos que trabaja con el modelo de base de datos de Postgress que lo que permite es eh ay regen un modelo de entidad relaci√≥n de cualquier cosa obviamente tienes oportunidad deme un momento ac√° tiene su oportunidad porque pues esto es como lo que estamos haciendo en este momento una demo ¬øqu√© consejo yo les doy de esto **√∫senlo como una fuente de inspiraci√≥n m√°s no como el resultado final** s√≠ cuando ustedes piden piden en digamos que trabajan con una herramienta como tal de AI siempre tienen que mirar a ella como un ayudante y no como el el que ejecute la tarea ¬ølisto entonces a ver si esto ya por fin conect√≥ perfecto entonces este para utilizar este database build lo √∫nico que hay que hacer es tener una cuenta de GitHub que ya he visto en las otras charlas que Pipe les ha comentado la importancia de tenerlo aqu√≠ b√°sicamente ¬øqu√© es lo que tenemos que hacer esperemos que est√° un poquito lento esto justo justo para la demo pero entonces ac√° lo que nosotros hacemos con esta herramienta es yo le escribo en medio de un promp obviamente aqu√≠ hay t√©cnicas de prompt y lo que √©l va a hacer es **generar un modelo de entidad relaci√≥n va a generar las tablas va a generar el SQL** yo le puedo pedir que genere inclusive los datos de escritura esp√©rate ver si esto carga a ver para tener ya una aplicaci√≥n digamos por as√≠ decirlo el backend ¬ølisto entonces esperemos a ver si esto carga mientras les cuento que cuando uno termina de colocar aqu√≠ el promp justo justo √©l tiene hay otra herramienta uno genera un en este supace que es la empresa tambi√©n una cuenta gratuita y uno puede generar un proyecto que tiene pues la forma de conectarse por tiene su app y dem√°s pero la idea aqu√≠ es que en lo que nosotros generemos en el chatbot √©l genera y despliega un modelo entidad relaci√≥n en una base de datos que est√° en la nube entonces eso ya nos permite por ejemplo si para la demo de ustedes necesitan probar algo que tenga conexi√≥n con con internet pueden digamos que utilizar esta herramienta esta aplicaci√≥n un momento porque ahora me hizo quedar mal mientras esto carga voy a responder una de las preguntas que ustedes me hac√≠an al comienzo y es el tema de cu√°l es el mejor modelo que tendr√≠a que yo utilizar ¬øcu√°l es el mejor Juan si yo en t√©rminos de desarrollo ¬øcu√°l es el mejor en texto los invito a que guarden esta p√°gina la experimenten despu√©s se llama **lmarena.ai** aaiai es buen√≠sima porque uno tiene un modo que se llama el **modo batalla** y b√°sicamente ustedes le piden cualquier cosa g√©n√©rame una imagen g√©n√©rame una tabla c√≥digo y √©l le genera dos tablas y les dice dos hace como dos chats le dice "Mire este es el chat X y este es el Y." Y ese es el resultado pin califique ¬øcu√°l le gust√≥ m√°s de acuerdo a esa calificaci√≥n y de acuerdo a la tarea es que se generan estos tipos de scores entonces digamos por ejemplo yo les dec√≠a que Gemini hasta hace muy poco o sea Gemini que era realmente digamos que es como el que yo m√°s utilizo era el n√∫mero uno para texto para desarrollo web pero ha cambiado y cambiaron las cosas y por ejemplo **GPT Hight es el que tiene mayor votaci√≥n** listo aqu√≠ est√° por ejemplo Cloud que tambi√©n lo preguntaron el modelo Opus est√° en el tercer lugar sin embargo si se dan cuenta **no necesariamente eso es algo tambi√©n importante y por eso les invito a que se vengan a esta p√°gina despu√©s pueden ver que no todos los modelos son buenos para el 100% de las cosas todav√≠a no son generalistas al 100%** ¬ølisto entonces ac√° lo que podemos ver es que por ejemplo eh para b√∫squeda o 3 sigue siendo mejor que cloud y Gemini 2.5 est√° en el segund casi como un empate en el segundo lugar pero para generar im√°genes por ejemplo GPT Image sigue siendo mucho mejor que otros que estaban por ah√≠ atr√°s que inclusive Gemina y dem√°s entonces esta paginita gu√°rdenla es muy interesante porque pues sirve para ustedes cuando est√©n de acuerdo al proyecto que ustedes vayan a hacer pueden validar ac√° tiene la opci√≥n de este leaderboard quiere decir esto como lo de acuerdo a los que al como al el ranking y esto les puede servir de acuerdo a lo que ustedes quieran hacer si tienen un proyecto que quisieran por ejemplo convertir im√°genes a texto pueden ir al al a modelo o este es el nivel general digamos que ac√° es donde se puede ver realmente es superinesante lo invito a que lo vean muchachos aqu√≠ por ejemplo temas de codificaci√≥n aqu√≠ va a salir clot por ah√≠ de segundo de tercero si mal no estoy porque pues es muy bueno en eso que era una de las preguntas que hac√≠an antes sobre este herramienta me qued√≥ mal les deo de verdad les debo aqu√≠ pero b√°sicamente lo que me me da me da como cosa porque ya lo ten√≠a cargado y todo ya ten√≠a aqu√≠ hecho unos modelos pero es b√°sicamente uno le genera ah mira aqu√≠ cargo uno no es el de no cargo el de el de el tracking de salud pero esto es b√°sicamente lo que quiero que vean que hace esta herramienta entonces digamos yo por ejemplo ac√° le dije que eh generara un modelo entidad relaci√≥n eran pruebas que yo estaba haciendo y era para un delivery de pedidos s√≠ entonces b√°sicamente...

**Pipe:** Dime qu√© pena Juan me muevo para esa llamada pero si quieres yo me quedo ac√° escuchando y te despides al final y cerramos no te preocupes que me est√°n esperando en otra llamada vale dale Pip dale y mira esos muchachos...

**Juan:** creo que ya me estoy d√©mos hasta las 15 y terminamos pero bueno primera herramienta entonces voy a ir rapid√≠simo entonces esta ac√° pru√©benla database build con un con un texto √©l les genera el modelo de entidad relaci√≥n les puede poblar los datos ac√° ustedes se pueden dar cuenta que uno puede digamos como tiene la el modelo completo esto lo aprende uno digamos yo ingeniero de sistemas lo aprend√≠ esto como hasta tercer semestre eh cuando uno le da deploy √©l hace el deploy de este modelo de entidad relaci√≥n en el en la p√°gina que les dec√≠a de Supase entonces genera todo esto en la tabla digamos como en la para que sea consumido de forma virtual entonces ah√≠ ir√≠a esta parte hm el tema de LM arena se los estaba mostrando este tambi√©n eh esta era la primera demo digamos que por tiempo y les ofrezco disculpas porque me emocion√© mucho al comienzo pero pues los invito a que prueben esto es la parte digamos la primera etapa de eso segunda parte de la demo fue lo de LM Arena digamos que LM Arena es super bueno por este sistema de calificaci√≥n que no lo hace una empresa no lo hace nadie pagado sino lo hace una comunidad entonces est√° buen√≠simo para que ustedes sepan escoger cu√°l es el mejor modelo y no le crean a Juan que lleva tanto tiempo trabajando sino que sea la comunidad que les diga eh los invito a que lo exploren para los que son muy muy t√©cnicos aqu√≠ hay una cantidad de informaci√≥n superinesante sobre las ventanas de contexto sobre los tokens sobre muchas cosas que hemos visto en esta charla entonces los invito a ello segundo punto eh relacionado con esa parte el tema de **Google Stitch** no s√© si han escuchado Google Stitch pero esto es una soluci√≥n muy buena que lo que hace es **hacer prototipado de interfaces web** entonces genera una aplicaci√≥n de tracking de salud enfocada mayores entonces esto es un producto de Google que en este momento est√° todav√≠a en fase beta eh hace parte de una suit de productos que tiene Google que est√°n enfocadas en c√≥mo generar eh interfaces prototipadas eh de interfaces y productos y aplicaciones web listo creo que estoy teniendo problemas de internet ¬øme pueden me escuchan bien creo que algo tengo como un delay ac√° ¬øme escuchan o ah verdad que no s√≠ ah√≠ ve la verdad que tiene cerrado el micr√≥fono perd√≥n entonces eh Google Stitch es un producto de Google super ch√©vere porque ac√° si se dan cuenta yo le escrib√≠ obviamente la idea como me estoy soltando todo lo que les expliqu√© pero la idea es que hagan un buen prom s√≠ de acuerdo al prom va a ser el resultado pero ac√° yo le dije que me generara como la la votaci√≥n que hicimos el tema de una aplicaci√≥n de tracking de salud entonces se van a dar cuenta los resultados tan interesantes que √©l genera **todo el c√≥digo** esto yo lo puedo exportar si digamos aqu√≠ hay gente que trae con el desarrollo web eh conocen Figma por ejemplo esto tiene la opci√≥n de hacer un el digamos de exportarlo a Figma y ah√≠ trabajar el resto de cosas toda esta informaci√≥n que ustedes ven ac√° todo esto es exportable los invito a que lo prueben todo se puede parametrizar digamos si yo quisiera por ejemplo decir oiga eh yo no quiero que la se√±ora sea una se√±ora estilo c√≥mic sino una foto todo eso se puede cambiar pero entonces ac√° lo interesante es que ac√° uno le puede decir puede iterar y puede decirle "Mire cambie las cosas." Si se dieron cuenta algo de lo que yo les dec√≠a que √©l hac√≠a en los modelos de pensamiento yo le di una petici√≥n √©l pens√≥ y √©l me dijo "Mire voy a generar estos diferentes pantallas son estos cuatro que est√°n ac√°." Si yo no hubiera querido le hubiera dicho "No no me interesa este en el registro yo quiero que tenga integraci√≥n con Facebook y dem√°s gen√©rame los botones." Esto ojo **esto no est√° haciendo el desarrollo** lo pero s√≠ les est√° ayudando en crear o en visualizar c√≥mo se podr√≠a ver la aplicaci√≥n de ustedes ¬ølisto va a haber una charla creo que es la siguiente esta que est√° enfocada en UA en UAU seguramente iban a tocar temas relacionados con estos pero pues est√° bueno que sepan que existe un producto que sirve para hacer este tipo de prototipados tambi√©n existe Gemini que Gemini como les dec√≠a es superinesante puede generar muchas cosas yo digamos ac√° eh por ejemplo parte de la informaci√≥n no s√© yo tengo ac√° la versi√≥n pro creo que la versi√≥n no est√° activa en todas las versiones pero est√° la opci√≥n **canvas** que lo con la opci√≥n canvas la presentaci√≥n parte de la presentaci√≥n que yo les mostr√© lo gener√© con esto se pueden dar cuenta Luis ac√° pero entonces les quer√≠a traer otra herramienta que les puede servir en caso de que la versi√≥n gratuita no tenga canvas y es que ustedes a Gemini le pueden decir que les genere una infograf√≠a que les genere el HTML y ustedes pueden coger el HTML lo genera as√≠ esto lo hace chat GPT lo hace cualquiera aqu√≠ obviamente aqu√≠ hay una mano de conocimiento que lo ideal es que no sean como yo y no copien y peguen pero hay otra herramienta que les puedo recomendar que les va a servir mucho para la jacat√≥n es una p√°gina tambi√©n gratuita tambi√©n tiene plan de pago pero pues en este caso para lo que necesitamos es suficiente que se llama **codepen** listo ¬øpara qu√© sirve esta herramienta sirve para por as√≠ decirlo si yo voy a un prompt y √©l me genera un HTML para yo poder sin necesidad de desplegarlo o guardarlo como un archivo y abrirlo de nuevo esta herramienta es como yo la uso bastante para hacer pruebas muy cortas de concepto y esto de una otra forma lo que permite es **visualizar renderizar el HTML el CSS o el JavaScript dentro del navegador sin que ustedes tengan que ir a instalar nada** ¬ølisto entonces esto le abre muchas posibilidades a pruebas r√°pidas o si por ejemplo ustedes est√°n en un contexto de probar ideas pueden tomar de stitch esto tiene la opci√≥n de exportar esto como HTML y ver c√≥mo le podr√≠an cambiar o mejorarle CSS es o el JavaScript que tenga un action button o lo que sea entonces esta es la segunda herramienta tambi√©n existe otra herramienta de Google yo les dec√≠a no es patrocinado pero a m√≠ me parece genial esta empresa y es **Google Collab** google Colab es superinesante porque de una otra forma lo que hace Google Collab es **alquilarnos google nos da un computador remoto** entonces para la gente digamos cuando nosotros eh eh tenemos un computador que no es el mejor como a veces a veces me pasa a m√≠ que se cuelga podemos utilizar Google Collab de forma gratuita hay unos l√≠mites pero aqu√≠ lo que hace es b√°sicamente **ejecutar c√≥digo de Python o DR en una m√°quina virtual de Google** ¬ølisto esto tambi√©n tiene seguramente un tracking m√°s avanzado pero pues si no la conocen los invito a que la exploren esto es muy √∫til y y yo c√≥mo les aconsejo que esto se enganche todo ustedes pueden generar en Google Stitch el frontend en esta database build eh la base de datos en Gemini pueden ayudar o sea ustedes tienen que crear c√≥digo pero pueden aqu√≠ generar fragmentos de Python que pueden llevar en Google Colab para probarlo y al final y ese si se los dejo como como una cascarita ya para que el que lo quiera buscar existe otro producto de Google se llama **Firebase Studio** que b√°sicamente lo que hace es eh eh desplegar aplicaciones completas entonces este de ac√° no se los explico se los dejo para el que sea curioso y lo quiera investigar eh existen existe Firebase Studio de Google que es una plataforma que de inicio a fin les permite generar cualquier tipo de aplicaci√≥n solo se paga cuando uno ya la publica en producci√≥n pero pues eso es un estadio mucho m√°s avanzado pero entonces con eso muchachos creo que voy a irme a la secci√≥n de dudas y preguntas mientras tanto quer√≠a agradecerles su tiempo gracias para los que se quedaron hasta este punto les ofrezco mis disculpas porque no sirvi√≥ muy bien la demo pero pues ah√≠ queda todo el material y todo para que lo exploren despu√©s ¬ølisto aqu√≠ creo que no hay m√°s Q&A o no lo veo entonces pues por ahora igual si tuvieran alguna pregunta con todo gusto eh estar√© para ayudarles la examinan con Pipe y conmigo podr√°n tener muchas muchas respuestas y pues nada aqu√≠ lo √∫nico que quiero decirles muchachos es que la invitaci√≥n y ya para cerrar es que **sean curiosos el futuro no lo va a cambiar la IA lo va a cambiar la gente curiosa que va a aprender a utilizar la IA** hay cosas que de pronto uno en este punto le dicen "Oiga peligroso tal cosa o ser√° que nos vamos a quedar sin trabajo creo que le√≠ que escribieron en alguna primera y la respuesta es que si uno no aprende a ser competitivo y no aprende a ser curioso lo m√°s probable es que s√≠." Entonces la idea es que ustedes sean agentes de cambio que no importa el caso el emprendimiento el conocimiento que tengan sean curiosos aprendan practiquen y aprovechen todas esas herramientas gratuitas que existen hoy d√≠a bueno les agradezco much√≠simo su tiempo espero pues nada alg√∫n feedback o algo que deseen compartirme por medio de Pipe y gracias gracias a todos los m√°s de 80 personas que se quedaron hasta este punto tengan todos muy buena tarde y estamos hablando muchos √©xitos en su carrera de aprendizaje muchachosa hasta luego.